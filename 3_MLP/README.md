# MLP

이 문서는 MNIST 데이터셋을 활용하여 다층 퍼셉트론(MLP) 모델을 구현하고 평가하는 방법을 제공합니다. 이 프로젝트는 다중 클래스 분류 문제를 해결하는 데 중점을 둡니다.

---

## 목차
1. [MLP 구현 (NumPy)](#mlp-구현-numpy)
2. [MLP 구현 (PyTorch)](#mlp-구현-pytorch)
3. [데이터 세부 정보](#데이터-세부-정보)
4. [결과 요약](#결과-요약)
---

## 개요

이 프로젝트는 다음 두 가지 방법으로 분류 모델을 구현하고 평가합니다:
1. NumPy를 사용한 다층 퍼셉트론(MLP).
2. PyTorch를 사용한 다층 퍼셉트론(MLP).

데이터는 MNIST 데이터셋(다중 클래스 분류)을 사용합니다.

---

## MLP 구현 (NumPy)

### 주요 내용
- **데이터 전처리**:
  - MNIST 데이터셋을 사용하여 다중 클래스 분류 문제로 변환.
  - 데이터를 28x28 이미지를 평탄화하여 입력으로 사용.
  - 픽셀 값을 0-1 범위로 정규화.

- **모델 학습**:
  - `relu` 활성화 함수와 `softmax` 출력 함수를 사용.
  - 경사 하강법을 통해 가중치와 편향 업데이트.

- **결과**:
  - 학습 후 손실이 점진적으로 감소.
  - 테스트 데이터에서 정확도: `79.98%`

---

## MLP 구현 (PyTorch)

### 주요 내용
- **데이터 전처리**:
  - MNIST 데이터셋을 사용하여 PyTorch 텐서로 변환.
  - `DataLoader`를 사용하여 배치 처리.

- **모델 정의**:
  - 두 개의 은닉층과 `ReLU` 활성화 함수를 사용하는 모델 정의.
  - 출력층에서 10개의 클래스 확률을 예측.

- **학습 및 평가**:
  - 손실 함수로 `CrossEntropyLoss`를 사용.
  - Adam 옵티마이저를 사용하여 학습.
  - 테스트 데이터에서 정확도: `98.10%`

- **결과**:
  - 학습 후 테스트 데이터에서 높은 정확도와 낮은 손실.
    ```
    Epoch [1/10], Loss: 0.0744
    Epoch [10/10], Loss: 0.0041
    ```

---

## 데이터 세부 정보

### MNIST 데이터셋
- **출처**: Keras의 MNIST 데이터셋.
- **특성 선택**:
  - 28x28 크기의 손글씨 이미지.
  - 픽셀 값을 0-1 범위로 정규화.
- **데이터 분할**:
  - 학습 데이터: 60,000개
  - 테스트 데이터: 10,000개

---

## 결과 요약

- NumPy와 PyTorch 모두 높은 정확도와 안정적인 손실 감소를 보여줌.
- PyTorch 구현은 학습 속도가 빠르고 확장성이 높음.
- MLP는 MNIST 데이터셋에서 `98.10%`의 높은 정확도를 달성.


