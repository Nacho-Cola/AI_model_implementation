{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzyTG5HPSHO2",
        "outputId": "2b81a678-e54b-4d63-e6c0-15bc8cd5237c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (50000, 32, 32, 3), dtype: float64\n",
            "y_train_onehot shape: (50000, 10), dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "# import cupy as np\n",
        "\n",
        "# 데이터 로드 (NumPy 배열로 로드됨)\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# 데이터 정규화 및 NumPy에서 CuPy로 변환\n",
        "X_train = np.array(X_train / 255.0)\n",
        "X_test = np.array(X_test / 255.0)\n",
        "\n",
        "# # 레이블을 원-핫 인코딩으로 변환 후 CuPy로 변환\n",
        "y_train_onehot = np.array(np.eye(10)[y_train.reshape(-1)])\n",
        "y_test_onehot = np.array(np.eye(10)[y_test.reshape(-1)])\n",
        "\n",
        "# # 확인\n",
        "print(f\"X_train shape: {X_train.shape}, dtype: {X_train.dtype}\")\n",
        "print(f\"y_train_onehot shape: {y_train_onehot.shape}, dtype: {y_train_onehot.dtype}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN:\n",
        "  def __init__(self):\n",
        "    self.layers = []\n",
        "    self.filters = []\n",
        "    self.weights = []\n",
        "    self.biases = []\n",
        "    self.caches = []\n",
        "\n",
        "  def add_conv_layer(self,num_filters, filter_size, input_depth, padding=0):\n",
        "    \"\"\"합성곱 레이어 추가\"\"\"\n",
        "    layer_filters = np.random.randn(num_filters, filter_size, filter_size, input_depth) * 0.01\n",
        "    self.filters.append(layer_filters)\n",
        "    self.layers.append(('conv',num_filters, filter_size, padding))\n",
        "\n",
        "  def add_pool_layer(self, pool_size=2, stride=2):\n",
        "    self.layers.append(('pool', pool_size, stride))\n",
        "\n",
        "  def add_dense_layer(self, input_size, output_size):\n",
        "    W = np.random.randn(input_size, output_size) * 0.01\n",
        "    b = np.zeros((1, output_size))\n",
        "    self.weights.append(W)\n",
        "    self.biases.append(b)\n",
        "    self.layers.append(('dense', input_size, output_size))\n",
        "\n",
        "  def pad(self, X, pad_size):\n",
        "    \"\"\"패딩 메서드: 입력에 패딩 추가\"\"\"\n",
        "    # 각 차원에 맞춰 패딩을 설정하며, 마지막 차원에는 패딩을 추가하지 않음\n",
        "    padding_shape = [(pad_size, pad_size) if i < X.ndim - 1 else (0, 0) for i in range(X.ndim)]\n",
        "    return np.pad(X, padding_shape, mode='constant', constant_values=0)\n",
        "\n",
        "\n",
        "  def relu(self, x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "  def relu_derivative(self, x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "  def softmax(self, x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "  def convolve(self, X, filters, padding=0):\n",
        "    # 배치가 있는 경우와 없는 경우를 처리\n",
        "    if len(X.shape) == 4:\n",
        "        batch_size, h, w, d = X.shape\n",
        "        outputs = []\n",
        "        for i in range(batch_size):\n",
        "            # 개별 샘플에 대해 패딩 및 합성곱 수행\n",
        "            output = self.convolve_single(X[i], filters, padding)\n",
        "            outputs.append(output)\n",
        "        return np.array(outputs)\n",
        "    else:\n",
        "        # 배치가 없는 경우 단일 이미지에 대해 합성곱 수행\n",
        "        return self.convolve_single(X, filters, padding)\n",
        "\n",
        "  def convolve_single(self, X, filters, padding=0):\n",
        "    \"\"\"단일 이미지에 대한 합성곱 연산\"\"\"\n",
        "    if padding > 0:\n",
        "      X = self.pad(X, padding)\n",
        "\n",
        "    h, w, d = X.shape\n",
        "    num_filters, filter_height, filter_width, _ = filters.shape\n",
        "    output_height = h - filter_height + 1\n",
        "    output_width = w - filter_width + 1\n",
        "    output = np.zeros((output_height, output_width, num_filters))\n",
        "\n",
        "    for f in range(num_filters):\n",
        "      filter = filters[f]\n",
        "      for i in range(output_height):\n",
        "        for j in range(output_width):\n",
        "          region = X[i:i + filter_height, j:j + filter_width, :]\n",
        "          output[i, j, f] = np.sum(region * filter)\n",
        "    return output\n",
        "\n",
        "  def pool(self, X, size=2, stride=2):\n",
        "    \"\"\"최대 풀링 연산 수행\"\"\"\n",
        "    h, w, d = X.shape\n",
        "    output = np.zeros((h//size, w//size, d))\n",
        "    for i in range(0, h, stride):\n",
        "      for j in rnage(0, w, stride):\n",
        "        output[i // stride, j // stride, :] = np.max(X[i:i + size, j:j + size, :], axis=(0, 1))\n",
        "    return output\n",
        "\n",
        "  def flatten(self, X):\n",
        "    \"\"\"Flatten 레이어\"\"\"\n",
        "    return X.reshape(1,-1)\n",
        "\n",
        "  def fully_connected(self, X, W, b):\n",
        "    \"\"\"완전 연결 연산\"\"\"\n",
        "    return np.dot(X, W) + b\n",
        "\n",
        "  def forward(self,X):\n",
        "    \"\"\"순전파: 추가된 레이어들을 순서대로 처리\"\"\"\n",
        "    out = X\n",
        "    self.cache = []\n",
        "    conv_layer_count = 0\n",
        "    dense_layer_count = 0\n",
        "\n",
        "    for layer in self.layers:\n",
        "      if layer[0] == 'conv':\n",
        "        num_filters, filter_size, padding = layer[1], layer[2], layer[3]\n",
        "        filters = self.filters[conv_layer_count]\n",
        "        out = self.convolve(out, filters, padding)\n",
        "        out = self.relu(out)\n",
        "        self.cache.append(out)\n",
        "        conv_layer_count += 1\n",
        "\n",
        "      elif layer[0] == 'pool':\n",
        "        pool_size, stride = layer[1], layer[2]\n",
        "        out = self.pool(out, pool_size, stride)\n",
        "        self.cache.append((out, pool_size, stride))\n",
        "\n",
        "      elif layer[0] == 'dense':\n",
        "        input_size, output_size, = layer[1], layer[2]\n",
        "        W, b = self.weights[dense_layer_count], self.biases[dense_layer_count]\n",
        "        if dense_layer_count == 0:\n",
        "          out = self.flatten(out)\n",
        "        out = self.fully_connected(out, W, b)\n",
        "        if dense_layer_count < len(self.weights) - 1:\n",
        "          out = self.relu(out)\n",
        "        self.cache.append(out)\n",
        "        denxe_layer_count += 1\n",
        "\n",
        "    out = self.softmax(out)\n",
        "    self.cache.append(out)\n",
        "    return out\n",
        "\n",
        "  def compute_loss(self, y_pred, y_true):\n",
        "    m = y_true.shape[0]\n",
        "    log_likelihood = -np.log(y_pred[range(m), ytrue])\n",
        "    return np.sum(log_likelihood) / m\n",
        "\n",
        "  def bakward(self, y, learning_rate=0.01):\n",
        "    \"\"\"역전파를 통한 기울기 계산 및 가중치 업데이트\"\"\"\n",
        "    d_out = self.cache.pop()\n",
        "    d_out[range(len(y)), y] -= 1\n",
        "\n",
        "    dense_layer_count = len(self.weigths) - 1\n",
        "    conv_layer_count = len(self.filters) - 1\n",
        "\n",
        "    for layer in reversed(self.layers):\n",
        "      if layer[0] =='dense':\n",
        "        dZ = d_out * self.relu_derivative(self.cache.pop())\n",
        "        dW = np.dot(self.cache[-1].T, dZ)\n",
        "        db = np.sum(dZ, axis=0, keepdims=True)\n",
        "        self.weigths[dense_layer_count] -= learning_rate * dW\n",
        "        self.biases[dense_layer_count] -= learning_rate * db\n",
        "        d_out = np.dot(dZ, self.weights[dense_layer_count].T)\n",
        "        dense_layer_count -= 1\n",
        "\n",
        "      elif layer[0] == 'pool':\n",
        "        d_out = self.pool_backward(d_out, self.cache.pop())\n",
        "\n",
        "      elif layer[0] == 'conv':\n",
        "        filters = self.filters[conv_layer_count]\n",
        "        d_out, d_filters = self.conv_backward(d_out, self.cache.pop(), filters)\n",
        "        self.filters[conv_layer_count] -= learning_rate * d_filters\n",
        "        conv_layer_count -= 1\n",
        "\n",
        "  def pool_backward(self, d_out, cache):\n",
        "    d_pool, pool_size, stride = np.zeros_like(cache[0]), cache[1], cache[2]\n",
        "    h, w, d = cache[0].shape\n",
        "    for i in range(0, h, stride):\n",
        "      for k in range(0, w, stride):\n",
        "        for k in range(d):\n",
        "          idx = np.unravel_index(np.argmax(cache[0][i:i + pool_size, j:j + pool_size, k]), (pool_size, pool_size))\n",
        "          d_pool[i+idx[0], j+idx[1], k] = d_out[i//stride, j//stride,k]\n",
        "    return d_pool\n",
        "\n",
        "  def conv_backward(self, d_out, cache, filters):\n",
        "    \"\"\"Convolution Layer 역전파\"\"\"\n",
        "    d_filters = np.zeros_like(filters)\n",
        "    h, w, d = cache.shape\n",
        "    num_filters, filter_height, filter_width, _ = filters.shape\n",
        "    d_conv = np.zeros_like(cahce)\n",
        "\n",
        "    for f in range(num_filters):\n",
        "      filter = filters[f]\n",
        "      for i in range(h - filter_height + 1):\n",
        "        for j in range(w - filter_width + 1):\n",
        "          for k in range(b):\n",
        "            region = cache[i:i + filter_height, j:j + filter_width, :]\n",
        "            d_filters[f, :, :, k] += region * d_out[i, j, f]\n",
        "            d_conv[i:i+filter_height, j:j+filter_width, k] += filter * d_out[i,j,f]\n",
        "    return d_conv, d_filters\n",
        "\n",
        "  def train(self, X, y, epochs=10, learning_rate=0.01):\n",
        "    for epoch in range(epochs):\n",
        "      y_pred = self.forward(X)\n",
        "      loss = self.compute_loss(y_pred, y)\n",
        "      print(f\"Epoch {epoch + 1}, Loss: {loss}\")\n",
        "      self.backward(y, learning_rate)\n",
        "\n",
        "  def predict(self, X):\n",
        "    y_pred = self.forward(X)\n",
        "    return np.argmax(y_pred, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4CA0woa8SdO7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = CNN()\n",
        "cnn.add_conv_layer(num_filters=8, filter_size=3, input_depth=3, padding=1)\n",
        "cnn.add_pool_layer(pool_size=2, stride=2)\n",
        "cnn.add_conv_layer(num_filters=16, filter_size=3, input_depth=8, padding=1)\n",
        "cnn.add_pool_layer(pool_size=2, stride=2)\n",
        "cnn.add_dense_layer(input_size=16 * 8 * 8, output_size=128)\n",
        "cnn.add_dense_layer(input_size=128, output_size=10)\n",
        "\n",
        "\n",
        "cnn.train(X_train, y_train_onehot, epochs=5, learning_rate=0.01)\n"
      ],
      "metadata": {
        "id": "Y7p0dFsXdKOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 예측 수행 (예시)\n",
        "y_pred = cnn.predict(X_test)\n",
        "y_test_cpu = y_test.get()  # CuPy 배열을 NumPy 배열로 변환\n",
        "y_pred_cpu = y_pred.get()  # CuPy 배열을 NumPy 배열로 변환\n",
        "\n",
        "# 혼동 행렬 계산\n",
        "conf_matrix = confusion_matrix(y_test_cpu, y_pred_cpu)\n",
        "\n",
        "# 혼동 행렬 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(10), yticklabels=range(10))\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix for CIFAR-10 Classification\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X63Ct7PxeUn4",
        "outputId": "819c0438-bb45-486a-dce3-d2231408f305"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단한 CNN 모델 생성 및 레이어 추가\n",
        "cnn = CNN()\n",
        "cnn.add_conv_layer(num_filters=8, filter_size=3, input_depth=3, padding=1)  # 하나의 합성곱 층\n",
        "cnn.add_pool_layer(pool_size=2, stride=2)                                   # 하나의 풀링 층\n",
        "cnn.add_dense_layer(input_size=8 * 16 * 16, output_size=128)                # 하나의 Dense 층 (flatten 후)\n",
        "cnn.add_dense_layer(input_size=128, output_size=10)                         # 출력층\n",
        "\n",
        "# 학습 수행\n",
        "cnn.train(X_train, y_train_onehot, epochs=5, learning_rate=0.01)\n"
      ],
      "metadata": {
        "id": "rMh_-NV2fOpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 예측 수행 (예시)\n",
        "y_pred = cnn.predict(X_test)\n",
        "y_test_cpu = y_test.get()  # CuPy 배열을 NumPy 배열로 변환\n",
        "y_pred_cpu = y_pred.get()  # CuPy 배열을 NumPy 배열로 변환\n",
        "\n",
        "# 혼동 행렬 계산\n",
        "conf_matrix = confusion_matrix(y_test_cpu, y_pred_cpu)\n",
        "\n",
        "# 혼동 행렬 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(10), yticklabels=range(10))\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix for CIFAR-10 Classification\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ap3qdtTETMJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rlWJCbmTkYOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
        "from keras.utils import clear_session\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "7C74YgCDkYAI"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clear_session()\n",
        "\n",
        "il = Input(shape = (32,32,3))\n",
        "\n",
        "hl = Conv2D(filters=8,\n",
        "            kernel_size = (3,3),\n",
        "            padding='same',\n",
        "            activation='relu'\n",
        "            )(il)\n",
        "\n",
        "hl = MaxPool2D(pool_size = (2,2),\n",
        "               strides = (2,2)\n",
        "               )(hl)\n",
        "\n",
        "hl = Conv2D(filters=16,\n",
        "            kernel_size = (3,3),\n",
        "            padding='same',\n",
        "            activation='relu'\n",
        "            )(hl)\n",
        "\n",
        "hl = MaxPool2D(pool_size = (2,2),\n",
        "               strides = (2,2)\n",
        "               )(hl)\n",
        "\n",
        "\n",
        "hl = Flatten()(hl)\n",
        "\n",
        "hl = Dense(128,  activation='relu')(hl)\n",
        "\n",
        "dr = Dropout(0.5)(hl)\n",
        "\n",
        "ol = Dense(10,  activation='softmax')(dr)\n",
        "\n",
        "\n",
        "model = Model(il, ol)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "8buEL8_bl_lJ",
        "outputId": "9e27aa94-232b-4fa1-b996-ab90210c3ede"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │             \u001b[38;5;34m224\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │           \u001b[38;5;34m1,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m131,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m133,882\u001b[0m (522.98 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,882</span> (522.98 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m133,882\u001b[0m (522.98 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,882</span> (522.98 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WndJOZy2n0iZ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor = 'val_loss', min_delta=0, patience=7, restore_best_weights=True )"
      ],
      "metadata": {
        "id": "8AYINx-tn87s"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(X_train, y_train_onehot, epochs = 10000, validation_split=.2, callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97Brulywn_5V",
        "outputId": "1caca486-37b6-4568-fdbf-be138f0a2a49"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.2725 - loss: 1.9671 - val_accuracy: 0.4837 - val_loss: 1.4356\n",
            "Epoch 2/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.4533 - loss: 1.4989 - val_accuracy: 0.5262 - val_loss: 1.3293\n",
            "Epoch 3/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5062 - loss: 1.3826 - val_accuracy: 0.5641 - val_loss: 1.2430\n",
            "Epoch 4/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 1.3156 - val_accuracy: 0.5736 - val_loss: 1.2003\n",
            "Epoch 5/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5453 - loss: 1.2656 - val_accuracy: 0.5920 - val_loss: 1.1572\n",
            "Epoch 6/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5693 - loss: 1.2048 - val_accuracy: 0.6032 - val_loss: 1.1258\n",
            "Epoch 7/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5768 - loss: 1.1792 - val_accuracy: 0.6143 - val_loss: 1.1058\n",
            "Epoch 8/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5873 - loss: 1.1539 - val_accuracy: 0.6231 - val_loss: 1.0792\n",
            "Epoch 9/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6050 - loss: 1.1093 - val_accuracy: 0.6319 - val_loss: 1.0593\n",
            "Epoch 10/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6045 - loss: 1.1029 - val_accuracy: 0.6195 - val_loss: 1.0925\n",
            "Epoch 11/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6131 - loss: 1.0737 - val_accuracy: 0.6342 - val_loss: 1.0454\n",
            "Epoch 12/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6273 - loss: 1.0442 - val_accuracy: 0.6395 - val_loss: 1.0390\n",
            "Epoch 13/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6331 - loss: 1.0313 - val_accuracy: 0.6473 - val_loss: 1.0271\n",
            "Epoch 14/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6344 - loss: 1.0179 - val_accuracy: 0.6438 - val_loss: 1.0259\n",
            "Epoch 15/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6424 - loss: 0.9992 - val_accuracy: 0.6374 - val_loss: 1.0334\n",
            "Epoch 16/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6449 - loss: 0.9862 - val_accuracy: 0.6483 - val_loss: 1.0165\n",
            "Epoch 17/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6502 - loss: 0.9710 - val_accuracy: 0.6499 - val_loss: 1.0185\n",
            "Epoch 18/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6524 - loss: 0.9641 - val_accuracy: 0.6531 - val_loss: 1.0180\n",
            "Epoch 19/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6572 - loss: 0.9509 - val_accuracy: 0.6566 - val_loss: 1.0309\n",
            "Epoch 20/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6614 - loss: 0.9413 - val_accuracy: 0.6547 - val_loss: 1.0229\n",
            "Epoch 21/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6697 - loss: 0.9248 - val_accuracy: 0.6536 - val_loss: 1.0283\n",
            "Epoch 22/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6695 - loss: 0.9179 - val_accuracy: 0.6598 - val_loss: 1.0121\n",
            "Epoch 23/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6770 - loss: 0.8989 - val_accuracy: 0.6543 - val_loss: 1.0195\n",
            "Epoch 24/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6766 - loss: 0.8938 - val_accuracy: 0.6591 - val_loss: 1.0162\n",
            "Epoch 25/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6780 - loss: 0.8828 - val_accuracy: 0.6471 - val_loss: 1.0543\n",
            "Epoch 26/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6830 - loss: 0.8735 - val_accuracy: 0.6564 - val_loss: 1.0271\n",
            "Epoch 27/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6869 - loss: 0.8673 - val_accuracy: 0.6548 - val_loss: 1.0258\n",
            "Epoch 28/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6881 - loss: 0.8623 - val_accuracy: 0.6587 - val_loss: 1.0360\n",
            "Epoch 29/10000\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6905 - loss: 0.8449 - val_accuracy: 0.6614 - val_loss: 1.0341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SiH8uLKTo4W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#torch"
      ],
      "metadata": {
        "id": "NhsnlFeG4giG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HiVirDqY3G13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "\n",
        "# CIFAR-10 데이터셋 로드\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# 데이터 정규화 (0-1 범위로 스케일링)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# 레이블을 원-핫 인코딩 없이 정수 형태로 변환\n",
        "y_train = y_train.reshape(-1)\n",
        "y_test = y_test.reshape(-1)\n",
        "\n",
        "# NumPy 배열을 PyTorch 텐서로 변환\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "KMrSH2FESaYU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# TensorDataset을 통해 입력과 레이블을 묶기\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# DataLoader 설정\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "TygOTOgwSndR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "t_hF_BTX4h7R"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleCNN, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "    self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "    self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "    x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "    x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "\n",
        "    #Flatten\n",
        "    x = x.view(-1, 128 * 4 * 4)\n",
        "\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "uKJVBco12ZN3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()"
      ],
      "metadata": {
        "id": "_s0O5JSG3CzK"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC-JmUR94oCf",
        "outputId": "3e08eb8e-4b1e-4b37-db88-cd7167996d4e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=2048, out_features=256, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"
      ],
      "metadata": {
        "id": "oUpzZKQSR_5n"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  for images, labels in train_loader:\n",
        "    output = model(images)\n",
        "\n",
        "    loss = criterion(output, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if not epoch%10:\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss : {loss.item():.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML_LvC4J4rZv",
        "outputId": "40d9c3c0-45e4-4fcf-a998-80ec7fde8b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss : 0.714551\n",
            "Epoch [11/100], Loss : 0.033514\n",
            "Epoch [21/100], Loss : 0.178189\n",
            "Epoch [31/100], Loss : 0.061476\n",
            "Epoch [41/100], Loss : 0.068716\n",
            "Epoch [51/100], Loss : 0.044403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P_bjnPXSTVgW"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}