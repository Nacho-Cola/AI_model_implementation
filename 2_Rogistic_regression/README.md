# README for Logistic Regression Models

이 문서는 Iris 데이터셋과 PyTorch를 사용하여 구현한 로지스틱 회귀 모델의 개요를 제공합니다. 로지스틱 회귀는 이진 분류 문제를 해결하기 위한 대표적인 기법으로, 이 문서에서는 Setosa 품종과 그 외 품종을 구분하는 과정을 보여줍니다.

---

## 목차
1. [개요](#개요)
2. [로지스틱 회귀 구현 (NumPy)](#로지스틱-회귀-구현-numpy)
3. [로지스틱 회귀 구현 (PyTorch)](#로지스틱-회귀-구현-pytorch)
4. [데이터 세부 정보](#데이터-세부-정보)
---

## 개요

이 프로젝트는 다음 두 가지 방법으로 로지스틱 회귀 모델을 구현하고 평가합니다:
1. NumPy를 사용한 기본 구현.
2. PyTorch를 사용한 심화 구현.

데이터는 Iris 데이터셋의 첫 두 개의 특성을 기반으로 하며, Setosa 품종과 비-Setosa 품종 간의 이진 분류를 수행합니다.

---

## 로지스틱 회귀 구현 (NumPy)

### 주요 내용
- **데이터 전처리**:
  - Iris 데이터셋에서 첫 두 개의 특성을 선택.
  - Setosa와 비-Setosa를 이진 분류 문제로 변환.
  - `StandardScaler`를 사용하여 데이터 표준화.

- **모델 학습**:
  - `sigmoid` 함수를 사용하여 로지스틱 회귀의 확률 계산.
  - 경사 하강법을 통해 모델 매개변수 업데이트.

- **결과**:
  - 정확도: 1.00
  - 혼동 행렬:
    ```
    [[20  0]
     [ 0 10]]
    ```
  - ROC 곡선 시각화를 통해 분류 성능 확인.

---

## 로지스틱 회귀 구현 (PyTorch)

### 주요 내용
- **데이터 전처리**:
  - PyTorch 텐서를 사용하여 데이터 변환.
  - `StandardScaler`를 사용하여 데이터 표준화.

- **모델 정의**:
  - `torch.nn.Linear`를 사용하여 모델 정의.
  - `torch.sigmoid`를 사용하여 확률 출력.

- **학습 및 평가**:
  - 손실 함수로 `BCELoss`(이진 교차 엔트로피 손실)를 사용.
  - SGD 옵티마이저를 사용하여 모델 매개변수 학습.
  - 테스트 손실: `0.1086`

- **결과**:
  - 학습 후 손실이 점진적으로 감소하며 안정적으로 수렴:
    ```
    Epoch [200/2000], Loss: 0.3906
    Epoch [400/2000], Loss: 0.2863
    ...
    Epoch [2000/2000], Loss: 0.1152
    ```

---

## 데이터 세부 정보

- **출처**: Scikit-learn의 Iris 데이터셋.
- **특성 선택**:
  - `sepal length (cm)`
  - `sepal width (cm)`
- **타겟 변환**:
  - Setosa = 1
  - none-Setosa = 0
- **데이터 분할**:
  - 학습 데이터: 80%
  - 테스트 데이터: 20%
- **전처리**:
  - `StandardScaler`를 사용하여 입력 데이터 표준화.

